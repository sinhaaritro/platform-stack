# ansible/site.yml
---
# This is the main playbook for the entire platform-stack project.
# It is organized into "plays", where each play targets a group of hosts
# from the inventory and applies the necessary roles to them.

# ==============================================================================
# PLAY 1: FOUNDATION LAYER
# Target: All Virtual Machines (Group: vm)
# Purpose: Universal configuration. Minimal footprint. No heavy runtimes.
# ==============================================================================
- name: Apply Base and Security Configuration
  hosts: vm
  become: true
  roles:
    - role: base          # System basics (Timezone, Locales, Packages)
    - role: security      # SSH Hardening, UFW, Fail2Ban
    - role: monitoring    # Node Exporter, QEMU Agent
    - role: users         # User creation, Git config, SSH Keys
    - role: storage_setup # Mount additional disks (e.g., /dev/sdb -> /data/storage)

# ==============================================================================
# PLAY 2: DEV/TEST KUBERNETES (KIND)
# Target: Kind (Kubernetes) Server
# Purpose: Ephemeral clusters. Manual app deployment for testing.
# ==============================================================================
- name: Configure Dev Kubernetes (Kind)
  hosts: kind
  become: true
  roles:
    - role: docker        # Runtime Dependency (Must run first)
    - role: k8s_repo      # Manage the official Kubernetes Apt repositories.
    - role: kind          # Cluster Manager (Provisions the cluster)
    - role: helm          # Package Manager (Only installs Helm)

# ==============================================================================
# PLAY 3A: PRODUCTION KUBERNETES - CONTROL PLANE BOOTSTRAP
# Target: Control Plane Nodes Only
# Purpose: Init Cluster, Install CNI, Generate Certs
# Serial: 1 ensures HA clusters initialize the 1st node completely
# before the 2nd/3rd node try to join it.
# ==============================================================================
- name: Bootstrap Control Plane (Init & CNI)
  hosts: k_control
  become: true
  serial: 1
  roles:
    - role: docker          # Ensure Runtime
    - role: k8s_repo        # Ensure Repos
    - role: kubeadm         # Ensure Binaries/Kernel
    - role: kubeadm_cluster # Execute Init/CNI/Control-Join
    - role: storage_local   # Setup Storage Class
    - role: helm            # Ensure Helm

# ==============================================================================
# PLAY 3B: PRODUCTION KUBERNETES - WORKER JOIN
# Target: Worker Nodes Only
# Purpose: Join the existing healthy cluster
# ==============================================================================
- name: Join Worker Nodes
  hosts: k_worker
  become: true
  # Parallel is fine here - all workers can join at once
  roles:
    - role: docker
    - role: k8s_repo
    - role: kubeadm
    - role: kubeadm_cluster # Execute Worker-Join

# ==============================================================================
# PLAY 4: PRODUCTION KUBERNETES - MANAGEMENT LAYER
# Target: The Hub Server Only (k_management)
# Purpose: Installs ArgoCD. (UI exposure and Fleet connect delayed).
# ==============================================================================
- name: Configure Management Layer (ArgoCD)
  hosts: k_management:&k_control
  become: true
  roles:
    - role: argocd

# # ==============================================================================
# # PLAY 5: WEB LAYER
# # Target: Web Server
# # ==============================================================================
# - name: Configure Web Server
#   hosts: server
#   become: true
#   roles:
#     - role: nginx

# # ==============================================================================
# # PLAY 6: DATA LAYER
# # Target: Postgres Database
# # ==============================================================================
# - name: Configure Postgres Database
#   hosts: postgres
#   become: true
#   roles:
#     - role: postgres
